{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <h1 style=\"color: #347AB7;\">Fine-Tuning <code style=\"background-color: #f5f5f5; color: #EB5424;\">Meta Llama2 13B model</code> with Amazon <code style=\"background-color: #f5f5f5; color: #EB5424;\">Bedrock</code></h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "<p style=\"font-size: 18px; text-align: left;\">Make sure you have executed this <a href=\"03.1_Initial_Setup.ipynb\" style=\"color: #347AB7; text-decoration: none; font-weight: bold;\"><code style=\"background-color: #f5f5f5; color: #EB5424;\">Initial setup</code> Notebook üìì.</a></p>\n",
    "\n",
    "In this notebook we demonstrate using Boto3 sdk for the fine-tuning and provisioning of [Llama2 13B](#https://ai.meta.com/llama/get-started/) model in Bedrock. You can also do this through the Bedrock Console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">1. Initial <code style=\"background-color: #f5f5f5; color: #EB5424;\">setup</code> ‚úÖ</h3>\n",
    "\n",
    "  <h4 style=\"color: #347AB7; margin-left: 20px;\"> a) Prepare the dataset for fine-tuning ‚úÖ</h4>\n",
    "\n",
    "  <h4 style=\"color: #347AB7; margin-left: 20px;\"> b) Upload the dataset to S3 ‚úÖ</h4>\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">2. Customize the <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code> with fine-tuning üé®</h3>\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">3. Provision the custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code> for inference üöÄ</h3>\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">4. Test the custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code>üî¨</h3>\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">5. Evaluate the Provisioned Custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code> üîé</h3>\n",
    "\n",
    "  <h3 style=\"color: #347AB7;\">6. Delete the provisioned model to <code style=\"background-color: #f5f5f5; color: #EB5424;\">save cost</code> üí∏</h3>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #347AB7;\">1. Initial <code style=\"background-color: #f5f5f5; color: #EB5424;\">setup</code> üõ†Ô∏è </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Fetching varialbes from `03.1_Initial_Setup.ipynb` notebook. \n",
    "\n",
    "%store -r role_arn\n",
    "%store -r s3_train_uri\n",
    "%store -r s3_validation_uri\n",
    "%store -r s3_test_uri\n",
    "%store -r bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'arn:aws:iam::507922848584:role/AmazonBedrockCustomizationRole1'\n",
      "'s3://bedrock-customization-us-east-1-507922848584/fine-tuning-datasets/train/train-cnn-5K.jsonl'\n",
      "'s3://bedrock-customization-us-east-1-507922848584/fine-tuning-datasets/validation/validation-cnn-1K.jsonl'\n",
      "'s3://bedrock-customization-us-east-1-507922848584/fine-tuning-datasets/test/test-cnn-10.jsonl'\n",
      "'bedrock-customization-us-east-1-507922848584'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pp(role_arn)\n",
    "pprint.pp(s3_train_uri)\n",
    "pprint.pp(s3_validation_uri)\n",
    "pprint.pp(s3_test_uri)\n",
    "pprint.pp(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "sts_client = boto3.client('sts')\n",
    "s3_client = boto3.client('s3')\n",
    "aws_account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "bedrock = boto3.client(service_name=\"bedrock\")\n",
    "bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file_name = \"test-cnn-10.jsonl\"\n",
    "data_folder = \"fine-tuning-datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">2. Customize the <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code> with fine-tuning üé®</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Fine-tuning job will take around 60mins to complete with 5K records.</div>\n",
    "\n",
    "Meta Llama2 customization hyperparameters: \n",
    "- `epochs`: The number of iterations through the entire training dataset and can take up any integer values in the range of 1-10, with a default value of 2.\n",
    "- `batchSize`: The number of samples processed before updating model parametersand can take up any integer values in the range of 1-64, with a default value of 1.\n",
    "- `learningRate`:\tThe rate at which model parameters are updated after each batch\twhich can take up a float value betweek 0.0-1.0 with a default value set to\t1.00E-5.\n",
    "- `learningRateWarmupSteps`: The number of iterations over which the learning rate is gradually increased to the specified rate and can take any integer value between 0-250 with a default value of 5.\n",
    "\n",
    "For guidelines on setting hyper-parameters refer to the guidelines provided [here](#https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-guidelines.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4a054273-0e70-4c63-be05-3ee15fc21658',\n",
       "  'HTTPStatusCode': 201,\n",
       "  'HTTPHeaders': {'date': 'Tue, 12 Mar 2024 02:50:55 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '112',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '4a054273-0e70-4c63-be05-3ee15fc21658'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:bedrock:us-east-1:507922848584:model-customization-job/meta.llama2-13b-v1:0:4k/qe5a9jvjc2j2'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "\n",
    "# Choose the foundation model you want to customize and provide ModelId(find more about model reference at https://docs.aws.amazon.com/bedrock/latest/userguide/bedrock-reference.html)\n",
    "base_model_id = \"meta.llama2-13b-v1:0:4k\"\n",
    "\n",
    "# Select the customization type from \"FINE_TUNING\" or \"CONTINUED_PRE_TRAINING\". \n",
    "customization_type = \"FINE_TUNING\"\n",
    "\n",
    "# Specify the roleArn for your customization job\n",
    "customization_role = role_arn\n",
    "\n",
    "# Create a customization job name\n",
    "customization_job_name = f\"llama2-finetune-sm-test-model-{ts}\"\n",
    "\n",
    "# Create a customized model name for your fine-tuned Llama2 model\n",
    "custom_model_name = f\"llama2-finetune-{ts}\"\n",
    "\n",
    "# Define the hyperparameters for fine-tuning Llama2 model\n",
    "hyper_parameters = {\n",
    "        \"epochCount\": \"2\",\n",
    "        \"batchSize\": \"1\",\n",
    "        \"learningRate\": \"0.00005\",\n",
    "    }\n",
    "\n",
    "# Specify your data path for training, validation(optional) and output\n",
    "training_data_config = {\"s3Uri\": s3_train_uri}\n",
    "\n",
    "# # uncomment the below section if you have validation dataset and provide the s3 uri for it. \n",
    "validation_data_config = {\n",
    "        \"validators\": [{\n",
    "            \"s3Uri\": s3_validation_uri\n",
    "        }]\n",
    "    }\n",
    "\n",
    "output_data_config = {\"s3Uri\": f's3://{bucket_name}/outputs/output-{custom_model_name}'}\n",
    "\n",
    "# # Create the customization job\n",
    "bedrock.create_model_customization_job(\n",
    "                                        customizationType=customization_type,\n",
    "                                        jobName=customization_job_name,\n",
    "                                        customModelName=custom_model_name,\n",
    "                                        roleArn=customization_role,\n",
    "                                        baseModelIdentifier=base_model_id,\n",
    "                                        hyperParameters=hyper_parameters,\n",
    "                                        trainingDataConfig=training_data_config,\n",
    "                                        validationDataConfig=validation_data_config,\n",
    "                                        outputDataConfig=output_data_config\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Customization Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=customization_job_name)[\"status\"]\n",
    "print(fine_tune_job)\n",
    "\n",
    "while fine_tune_job == \"InProgress\":\n",
    "    time.sleep(60)\n",
    "    fine_tune_job = bedrock.get_model_customization_job(jobIdentifier=customization_job_name)[\"status\"]\n",
    "    print (fine_tune_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Custom Model\n",
    "Once the customization job is finished, you can check your existing custom model(s) and retrieve the modelArn of your fine-tuned Llama2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '54bf8be4-efd7-46f6-9593-e25421437af4',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Tue, 12 Mar 2024 03:52:57 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '371',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '54bf8be4-efd7-46f6-9593-e25421437af4'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1:507922848584:custom-model/meta.llama2-13b-v1:0:4k/yorojec81ro9',\n",
       "   'modelName': 'llama2-finetune-2024-03-12-02-50-55',\n",
       "   'creationTime': datetime.datetime(2024, 3, 12, 2, 50, 55, 973000, tzinfo=tzlocal()),\n",
       "   'baseModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k',\n",
       "   'baseModelName': '',\n",
       "   'customizationType': 'FINE_TUNING'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can list your custom models using the command below\n",
    "bedrock.list_custom_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please make sure your customization job status is \"completed\" before proceeding to retrieve the modelArn, otherwise you will run into errors. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the modelArn of the fine-tuned model\n",
    "fine_tune_job = bedrock.get_custom_model(modelIdentifier=custom_model_name)\n",
    "custom_model_id = fine_tune_job['modelArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model-customization-job-qe5a9jvjc2j2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_job_name = \"model-customization-job-\"+fine_tune_job['jobArn'].split('/')[-1]\n",
    "output_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training and Validation Loss\n",
    "Now that we have completed fine-tuning job, lets visualize our results to see if our job is not underfitting or overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model customization job metrics from S3 and plot the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metrics_path = f\"fine-tuning-datasets/{output_job_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $output_metrics_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_s3_prefix=f'outputs/output-{custom_model_name}/{output_job_name}/training_artifacts/step_wise_training_metrics.csv'\n",
    "validation_metrics_s3_prefix=f'outputs/output-{custom_model_name}/{output_job_name}/validation_artifacts/post_fine_tuning_validation/validation/validation_metrics.csv'\n",
    "\n",
    "train_metrics_name='train_metrics.csv'\n",
    "validation_metrics_name='validation_metrics.csv'\n",
    "\n",
    "train_file_name_local=output_metrics_path+'/'+train_metrics_name\n",
    "validation_file_name_local=output_metrics_path+'/'+validation_metrics_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.download_file(bucket_name, train_metrics_s3_prefix, train_file_name_local)\n",
    "s3_client.download_file(bucket_name, validation_metrics_s3_prefix, validation_file_name_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_file_name_local)\n",
    "'''The training loss is at an iteration level. To calculate loss at the epoch level,\n",
    "    average the iteration-level loss for each epoch'''\n",
    "train_metrics_epoch=train_data.groupby('epoch_number').mean()\n",
    "validation_metrics_epoch=pd.read_csv(validation_file_name_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_metrics_epoch.epoch_number, validation_metrics_epoch.validation_loss,label='validation')\n",
    "plt.plot(train_metrics_epoch.index, train_metrics_epoch.training_loss,label='training')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">3. Provision the custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code> for inference üöÄ</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Creating provisioned throughput will take around 20-30mins to complete.</div>\n",
    "\n",
    "You will need to create provisioned throughput to be able to evaluate the model performance. You can do so through the [console](https://docs.aws.amazon.com/bedrock/latest/userguide/prov-cap-console.html) or use the following api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the provision throughput job and retrieve the provisioned model id\n",
    "provisioned_model_id = bedrock.create_provisioned_model_throughput(\n",
    "     modelUnits=1,\n",
    "    # create a name for your provisioned throughput model\n",
    "     provisionedModelName='test-model-v1-001', \n",
    "     modelId=custom_model_id\n",
    "    )['provisionedModelArn']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "Creating\n",
      "InService\n"
     ]
    }
   ],
   "source": [
    "# check provisioned throughput job status\n",
    "import time\n",
    "status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId = provisioned_model_id)['status'] \n",
    "while status_provisioning == 'Creating':\n",
    "    time.sleep(60)\n",
    "    status_provisioning = bedrock.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id)['status']\n",
    "    print(status_provisioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">4. Test the custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">model</code>üî¨</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Invoke the privisioned custom model.You can replace the follwing prompt_txt with the prompts that are more similar to your fine-tuning dataset, this helps to check whether the fine-tuned model is performing as you expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please make sure your provisioned throughput job status becomes InService before proceeding. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Provide the prompt text \n",
    "test_file_path = f'{data_folder}/{test_file_name}'\n",
    "with open(test_file_path) as f:\n",
    "    lines = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "instruction:\n",
      "\n",
      "Summarize the news article provided below.\n",
      "\n",
      "input:\n",
      "\n",
      "The National Trust has replaced antique furniture with beanbags at one of its historic homes in an ‚Äòexperiment‚Äô which has enraged heritage experts. Furniture dating back to 1820 was moved from the library at Ickworth House in Suffolk earlier this year and replaced with four brown leatherette bean bags. The move was designed to encourage visitors to ‚Äòdwell and take in the atmosphere‚Äô in the room but it provoked fury from heritage expects who branded the move ‚Äòmisguided‚Äô. The National Trust has replaced antique furniture with beanbags in the library of Ickworth House, Suffolk . Now it has emerged that similar experiments will take place at nine other of its venues around the country. Art historian Bendor Grosvenor, whose blog post on his Art History News site about Ickworth sparked the controversy, told The Independent: ‚ÄòI suspect the hoo-ha about the beanbags may at least cause them rethink what they were going to do. The National Trust said the beanbag experiment was 'short-term' Pictured: Ickworth House, Suffolk . ‚ÄòI don‚Äôt think you‚Äôll ever bring in a new audience by talking down to it. Experimentation and bringing in new audiences are marvellous but there are better ways of doing it by taking away things people might want to see. It‚Äôs patronising nonsense.‚Äô The National Trust‚Äôs director of strategy, curatorship and external affairs Simon Murray told The Art Newspaper that the Trust ‚Äòpresents each house in context‚Äô and that each is different and treated appropriately. He said: ‚ÄòWe are not a museum that takes objects, shows them in a display case, shines a light on them and labels them‚Äô. But he said this meant that ‚Äòmany visitors find a vast array of objects in front of them, cast a cursory eye over them and don‚Äôt get a great deal from the experience.‚Äô He said the beanbag experiment was a short-term arrangement which would not necessarily continue for the whole year. But he added: ‚ÄòSome of our staff think we should have used a rather different sort of seating and others think it is good as an experiment.‚Äô\n",
      "\n",
      "response:\n",
      "\n",
      "Four brown leatherette bean bags placed in library at Ickworth House .\n",
      "Furniture dating nearly 200 years removed to make way for bean bags .\n",
      "Designed to encourage visitors to 'dwell and take in atmosphere'\n",
      "Art historian brands the experiment 'patronising nonsense'\n"
     ]
    }
   ],
   "source": [
    "test_prompt = json.loads(lines[0])['prompt']\n",
    "reference_summary = json.loads(lines[0])['completion']\n",
    "print(test_prompt)\n",
    "print()\n",
    "print(reference_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct model input following the format needed by Llama2 model following instructions [here](#https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-meta.html).\n",
    "Please pay attention to the \"Model invocation request body field\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generation': ' response:\\n'\n",
      "               '\\n'\n",
      "               'Beanbags have replaced antique furniture in the library at '\n",
      "               'Ickworth House .\\n'\n",
      "               'The National Trust said the move was designed to encourage '\n",
      "               \"visitors to 'dwell and take in the atmosphere'\\n\"\n",
      "               \"But heritage experts have branded the move 'misguided'\",\n",
      " 'generation_token_count': 63,\n",
      " 'prompt_token_count': 535,\n",
      " 'stop_reason': 'stop'}\n"
     ]
    }
   ],
   "source": [
    "body = json.dumps({\n",
    "    \"prompt\": test_prompt,\n",
    "    # specify the parameters as needed\n",
    "    \"max_gen_len\": 200,\n",
    "    \"temperature\": 0.4,\n",
    "    \"top_p\": 0.3,\n",
    "})\n",
    "\n",
    "# provide the modelId of the provisioned custom model\n",
    "modelId = provisioned_model_id\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "# invoke the provisioned custom model\n",
    "response = bedrock_runtime.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "pprint(response_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">5. Evaluate the Provisioned Custom <code style=\"background-color: #f5f5f5; color: #EB5424;\">Model</code> üîé</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [fmeval](https://github.com/aws/fmeval) as the framework to create an evaluation workflow for our fine-tuned model.\n",
    "\n",
    "FMEval is a library to evaluate Large Language Models (LLMs) and select the best LLM for your use case. The library can help evaluate LLMs for the following tasks:\n",
    "\n",
    "- Open-ended generation - the production of natural language as a response to general prompts that do not have a pre-defined structure.\n",
    "- Text summarization - summarizing the most important parts of a text, shortening a text while preserving its meaning.\n",
    "- Question Answering - the generation of a relevant and accurate response to a question.\n",
    "- Classification - assigning a category, such as a label or score, to text based on its content.\n",
    "\n",
    "For our dataset we will leverage the `Text summarization` metrics namely `METEOR`, `ROUGE`, and `BERT` score. \n",
    "\n",
    "- `ROUGE`: The metrics compare an automatically produced summary or translation against a reference or a set of references (human-produced) summary or translation. ROUGE metrics range between 0 and 1, with higher scores indicating higher similarity between the automatically produced summary and the reference. [Wikipedia link](#https://en.wikipedia.org/wiki/ROUGE_(metric))\n",
    "- `BERTScore`: calculates the similarity between a summary and reference texts based on the outputs of BERT (Bidirectional Encoder Representations from Transformers), a powerful language model. [Medium article link](#https://haticeozbolat17.medium.com/bertscore-and-rouge-two-metrics-for-evaluating-text-summarization-systems-6337b1d98917)\n",
    "- `METEOR`: computes a score that represents the semantic alignment and similarity between the so-called reference (original content) and the candidate (summary) sentences. For this, it takes into account both, exact word matches and similar word changes, that preserve the same meaning. [MDPI documentation](#https://www.mdpi.com/2673-2688/4/4/49#:~:text=METEOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Check that the dataset file to be used by the evaluation is present\n",
    "if not glob.glob(\"./fine-tuning-datasets/test-cnn-10.jsonl\"):\n",
    "    print(\"ERROR - please make sure the file, your_evaluation_data_set.jsonl, exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "from fmeval.model_runners.bedrock_model_runner import BedrockModelRunner\n",
    "from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "from fmeval.eval_algorithms.summarization_accuracy import SummarizationAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Config Setup\n",
    "\n",
    "Below, we create a DataConfig for the local dataset file, xsum_sample.jsonl.\n",
    "- `dataset_name` is just an identifier for your own reference\n",
    "- `dataset_uri` is either a local path to a file or an S3 URI\n",
    "- `dataset_mime_type` is the MIME type of the dataset. Currently, JSON and JSON Lines are supported.\n",
    "- `model_input_location` and `target_output_location` are JMESPath queries used to find the model inputs and target outputs within the dataset. The values that you specify here depend on the structure of the dataset itself. Take a look at xsum_sample.jsonl to see where \"document\" and \"summary\" show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"fine-tuning-datasets\"\n",
    "config = DataConfig(\n",
    "                    dataset_name=test_file_name,\n",
    "                    dataset_uri=test_file_path,\n",
    "                    dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "                    model_input_location=\"prompt\",\n",
    "                    target_output_location=\"completion\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Bedrock Model Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_model_runner = BedrockModelRunner(\n",
    "                                            model_id=provisioned_model_id,\n",
    "                                            # 'generation' is the field name for response content generated by the fine-tuned and provisioned model (see output formats of Llama2 models follows https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-meta.html - \"Model invocation response body field\")\n",
    "                                            output='generation',\n",
    "                                            # content_template is the input formats of Llama2 model\n",
    "                                            content_template='{\"prompt\": $prompt, \"max_gen_len\": 50, \"temperature\": 0.1, \"top_p\": 0.3}',\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model Evaluation Job\n",
    "\n",
    "In this section, we will create an evaluation job using `SummaryAccuracy` class from `fmeval` package with `METEOR, ROUGE, and BERTScores`. \n",
    "Please note that this is a sample notebook where we have fine-tuned the model with 5K records and for 2 epochs with learning rate of `0.00005`. For your use case and based on your dataset, when you will fine-tune the model with relevant number of records, and epochs, you might see different results than in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "2024-03-12 04:07:39,418\tWARNING services.py:1889 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 8323915776 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-03-12 04:07:39,465\tINFO worker.py:1642 -- Started a local Ray instance.\n",
      "2024-03-12 04:07:47,770\tINFO read_api.py:406 -- To satisfy the requested parallelism of 32, each read task output is split into 32 smaller blocks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:07:56,040\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-12 04:07:56,041\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:07:56,041\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Repartition 1:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split Repartition 2:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:07:56,207\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)]\n",
      "2024-03-12 04:07:56,208\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:07:56,208\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(MapBatches(process_batch) pid=11976)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "\u001b[2m\u001b[36m(MapBatches(process_batch) pid=11976)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:08:03,295\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-12 04:08:03,296\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:08:03,296\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-12 04:08:03,386\tINFO actor_pool_map_operator.py:106 -- Map(ModelRunnerWrapper): Waiting for 15 pool actors to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_MapWorker pid=12730)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[32m [repeated 15x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_MapWorker pid=12730)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:08:30,384\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-12 04:08:30,384\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:08:30,385\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Map(_generate_eval_scores) pid=13321)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Map(_generate_eval_scores) pid=13321)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Map(_generate_eval_scores) pid=13319)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Map(_generate_eval_scores) pid=13319)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BertscoreHelperModel pid=12405)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(BertscoreHelperModel pid=12405)\u001b[0m   query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "\u001b[2m\u001b[36m(BertscoreHelperModel pid=12405)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\u001b[2m\u001b[36m(BertscoreHelperModel pid=12405)\u001b[0m   p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n",
      "2024-03-12 04:10:21,027\tINFO dataset.py:2380 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-03-12 04:10:21,028\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-12 04:10:21,028\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:10:21,029\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:10:21,227\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-12 04:10:21,228\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:10:21,229\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:10:21,388\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-12 04:10:21,389\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:10:21,390\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:10:21,557\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-12 04:10:21,557\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:10:21,558\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 04:10:21,767\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-12 04:10:21,768\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-12 04:10:21,768\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prompt_template is a template for prompt, if you would like to change the prompt to see how it affects the model peformance of your fine-tuned model, you can play around with\n",
    "# this parameter. E.g. for an Anthropic Claude model, this could be prompt_template_txt=\"Human: $feature\\n\\nAssistant:\\n\"\n",
    "# the value \"$feature\" is a placeholder when you have nothing to add to the prompt on top of the \"prompt\" field in your fine-tuning data.\n",
    "prompt_template_txt = \"$feature\"\n",
    "\n",
    "# call the SummarizationAccuracy class to create the evaluation job with METEOR, ROUGE, and BERT scores\n",
    "eval_algo = SummarizationAccuracy()\n",
    "eval_output = eval_algo.evaluate(model=bedrock_model_runner, dataset_config=config, prompt_template=prompt_template_txt, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"eval_name\": \"summarization_accuracy\",\n",
      "        \"dataset_name\": \"test-cnn-10.jsonl\",\n",
      "        \"dataset_scores\": [\n",
      "            {\n",
      "                \"name\": \"meteor\",\n",
      "                \"value\": 0.39435233359905386\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"rouge\",\n",
      "                \"value\": 0.2679509674783136\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"bertscore\",\n",
      "                \"value\": 0.7136923491954803\n",
      "            }\n",
      "        ],\n",
      "        \"prompt_template\": \"$feature\",\n",
      "        \"category_scores\": null,\n",
      "        \"output_path\": \"/tmp/eval_results/summarization_accuracy_test-cnn-10.jsonl.jsonl\",\n",
      "        \"error\": null\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Pretty-print the evaluation output (notice the score).\n",
    "import json\n",
    "print(json.dumps(eval_output, default=vars, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_output</th>\n",
       "      <th>target_output</th>\n",
       "      <th>prompt</th>\n",
       "      <th>scores</th>\n",
       "      <th>eval_algo</th>\n",
       "      <th>eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nFloyd Mayweather's fight against...</td>\n",
       "      <td>response:\\n\\nUS viewers will have to pay up to...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.205255050011933...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.664433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nNew York state authorities have ...</td>\n",
       "      <td>response:\\n\\nNew York reports 160 hospitalizat...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.460460460460460...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.751766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nBadou Jack outpointed Anthony Di...</td>\n",
       "      <td>response:\\n\\nBadou Jack beat Anthony Dirrell o...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.362090848960474...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.652971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nChange4Life is promoting dishes ...</td>\n",
       "      <td>response:\\n\\nChange4Life run by Public Health ...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.550965403997508...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.769306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nBeanbags have replaced antique f...</td>\n",
       "      <td>response:\\n\\nFour brown leatherette bean bags ...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.459532332295104...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.744286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nYahya Rashid, 19, was arrested a...</td>\n",
       "      <td>response:\\n\\nLondon's Metropolitan Police say ...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.451971746403957...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.802406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nRoberto Carlos has revealed his ...</td>\n",
       "      <td>response:\\n\\nRoberto Carlos says the pressures...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.298463356973995...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.677269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nBilly Vunipola cited for strikin...</td>\n",
       "      <td>response:\\n\\nEngland No 8 cited for incident i...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.290874932903918...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.696025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nFilipe Luis insists he wants to ...</td>\n",
       "      <td>response:\\n\\nFilipe Luis signed for Chelsea fr...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.576884294332211...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.748076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>response:\\n\\nDale Cregan is on hunger strike ...</td>\n",
       "      <td>response:\\n\\n31-year-old was transferred to so...</td>\n",
       "      <td>Below is an instruction that describes a task,...</td>\n",
       "      <td>[{'name': 'meteor', 'value': 0.287024909650973...</td>\n",
       "      <td>bertscore</td>\n",
       "      <td>0.630384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         model_input  \\\n",
       "0  Below is an instruction that describes a task,...   \n",
       "1  Below is an instruction that describes a task,...   \n",
       "2  Below is an instruction that describes a task,...   \n",
       "3  Below is an instruction that describes a task,...   \n",
       "4  Below is an instruction that describes a task,...   \n",
       "5  Below is an instruction that describes a task,...   \n",
       "6  Below is an instruction that describes a task,...   \n",
       "7  Below is an instruction that describes a task,...   \n",
       "8  Below is an instruction that describes a task,...   \n",
       "9  Below is an instruction that describes a task,...   \n",
       "\n",
       "                                        model_output  \\\n",
       "0   response:\\n\\nFloyd Mayweather's fight against...   \n",
       "1   response:\\n\\nNew York state authorities have ...   \n",
       "2   response:\\n\\nBadou Jack outpointed Anthony Di...   \n",
       "3   response:\\n\\nChange4Life is promoting dishes ...   \n",
       "4   response:\\n\\nBeanbags have replaced antique f...   \n",
       "5   response:\\n\\nYahya Rashid, 19, was arrested a...   \n",
       "6   response:\\n\\nRoberto Carlos has revealed his ...   \n",
       "7   response:\\n\\nBilly Vunipola cited for strikin...   \n",
       "8   response:\\n\\nFilipe Luis insists he wants to ...   \n",
       "9   response:\\n\\nDale Cregan is on hunger strike ...   \n",
       "\n",
       "                                       target_output  \\\n",
       "0  response:\\n\\nUS viewers will have to pay up to...   \n",
       "1  response:\\n\\nNew York reports 160 hospitalizat...   \n",
       "2  response:\\n\\nBadou Jack beat Anthony Dirrell o...   \n",
       "3  response:\\n\\nChange4Life run by Public Health ...   \n",
       "4  response:\\n\\nFour brown leatherette bean bags ...   \n",
       "5  response:\\n\\nLondon's Metropolitan Police say ...   \n",
       "6  response:\\n\\nRoberto Carlos says the pressures...   \n",
       "7  response:\\n\\nEngland No 8 cited for incident i...   \n",
       "8  response:\\n\\nFilipe Luis signed for Chelsea fr...   \n",
       "9  response:\\n\\n31-year-old was transferred to so...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Below is an instruction that describes a task,...   \n",
       "1  Below is an instruction that describes a task,...   \n",
       "2  Below is an instruction that describes a task,...   \n",
       "3  Below is an instruction that describes a task,...   \n",
       "4  Below is an instruction that describes a task,...   \n",
       "5  Below is an instruction that describes a task,...   \n",
       "6  Below is an instruction that describes a task,...   \n",
       "7  Below is an instruction that describes a task,...   \n",
       "8  Below is an instruction that describes a task,...   \n",
       "9  Below is an instruction that describes a task,...   \n",
       "\n",
       "                                              scores  eval_algo  eval_score  \n",
       "0  [{'name': 'meteor', 'value': 0.205255050011933...  bertscore    0.664433  \n",
       "1  [{'name': 'meteor', 'value': 0.460460460460460...  bertscore    0.751766  \n",
       "2  [{'name': 'meteor', 'value': 0.362090848960474...  bertscore    0.652971  \n",
       "3  [{'name': 'meteor', 'value': 0.550965403997508...  bertscore    0.769306  \n",
       "4  [{'name': 'meteor', 'value': 0.459532332295104...  bertscore    0.744286  \n",
       "5  [{'name': 'meteor', 'value': 0.451971746403957...  bertscore    0.802406  \n",
       "6  [{'name': 'meteor', 'value': 0.298463356973995...  bertscore    0.677269  \n",
       "7  [{'name': 'meteor', 'value': 0.290874932903918...  bertscore    0.696025  \n",
       "8  [{'name': 'meteor', 'value': 0.576884294332211...  bertscore    0.748076  \n",
       "9  [{'name': 'meteor', 'value': 0.287024909650973...  bertscore    0.630384  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pandas DataFrame to visualize the results\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# We obtain the path to the results file from \"output_path\" in the cell above\n",
    "with open(f\"/tmp/eval_results/summarization_accuracy_test-cnn-10.jsonl.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)\n",
    "df['eval_algo'] = df['scores'].apply(lambda x: x[2]['name'])\n",
    "df['eval_score'] = df['scores'].apply(lambda x: x[2]['value'])\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #347AB7;\">6. Delete the provisioned model to <code style=\"background-color: #f5f5f5; color: #EB5424;\">save cost</code> üí∏</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Please make sure to delete providsioned throughput with the following code as there will be cost incurred if its left in running state, even if you are not using it. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the provisioned throughput\n",
    "bedrock.delete_provisioned_model_throughput(provisionedModelId=provisioned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please finish up the cleaning process by running 03_cleanup.ipynb to clean up the other resources. </div>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.c5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
