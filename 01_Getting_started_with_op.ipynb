{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331d43e6-031d-4dc3-ba24-eeb453a14055",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<h1 style=\"color: #347AB7;\">Getting Started with Amazon <code style=\"background-color: #f5f5f5; color: #EB5424;\">Bedrock</code></h1>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d55a7d-204a-4738-904a-2da5a695fb82",
   "metadata": {},
   "source": [
    "With the Amazon `Bedrock` serverless experience, you can quickly get started, easily experiment with FMs, privately customize FMs with your own data, and seamlessly integrate and deploy them into your applications using AWS tools and capabilities.\n",
    "\n",
    "**Foundation models**\n",
    "\n",
    "Amazon Bedrock supports foundation models from industry-leading providers. Choose the model that is best suited to achieving your unique goals.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/fms.png\" alt=\"Claude 3 Benchmark\" style=\"width: 80%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663824a5-17c9-4d6a-815f-a53f0dbae00e",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #347AB7;\">Introduction to <code style=\"background-color: #f5f5f5; color: #EB5424;\">Claude 3</code> on Amazon <code style=\"background-color: #f5f5f5; color: #EB5424;\">Bedrock</code></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c09326-f573-40a9-8f90-d02e2ea1a010",
   "metadata": {},
   "source": [
    "<p>Anthropic is proud to announce <strong style=\"color: #347AB7;\">Claude 3</strong>, a new family of state-of-the-art AI models that redefine the possibilities for customizing artificial intelligence to meet specific business needs. This innovative offering allows customers to select the perfect blend of intelligence, speed, and cost-effectiveness for their unique requirements. The Claude 3 family consists of three distinct models:</p>\n",
    "\n",
    "<ul>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Haiku</code></strong>: The epitome of efficiency and speed. Designed for near-instant responsiveness, Haiku is the fastest and most compact model, perfect for applications requiring immediate feedback without compromising on performance.</li>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Sonnet</code></strong>: The ideal compromise. Sonnet offers a balanced mix of capabilities and speed, making it the go-to model for businesses seeking a harmonious blend of performance and efficiency.</li>\n",
    "    <li><strong>Claude 3 <code style=\"background-color: #f5f5f5; color: #EB5424;\">Opus</code></strong>: The pinnacle of intelligence. Opus is engineered for top-level performance on the most complex tasks, offering unparalleled intelligence and capability for the most demanding business applications.</li>\n",
    "</ul>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/claude3_bm.png\" alt=\"Claude 3 Benchmark\" style=\"width: 50%;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdea909-83eb-4aac-8580-b5eb6a06641d",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #347AB7;\">Now Available in Amazon Bedrock</h2>\n",
    "\n",
    "<p><strong style=\"color: #347AB7;\">Anthropicâ€™s Claude 3 Sonnet</strong> is now available in Amazon Bedrock, with Claude 3 Opus and Claude 3 Haiku coming soon. The integration of Claude 3 Sonnet within Amazon Bedrock paves the way for the development of cost-effective, intelligent, reliable, and speedy generative AI applications tailored for enterprise needs.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799230e-e223-4a3a-9e87-0c41d693a4ba",
   "metadata": {},
   "source": [
    "Let's get started with Claude using Bedrock. \n",
    "- Amazon Bedrock `UI` \n",
    "- AWS SDK using `boto3`\n",
    "- Deploy your **own chatbot** using Amazon Bedrock deployed on `AWS`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb93100-3b11-4e37-b796-e7b8dc3a4495",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">Amazon Bedrock UI</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9197ff-b6f5-41f4-94e2-c994877356a2",
   "metadata": {},
   "source": [
    "Let's jump into the [Amazon Bedrock Console](https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cabda5-ed74-4d41-bbb2-2662140358b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">AWS SDK using boto3</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5add282-3520-4c30-a62c-324751efdb2f",
   "metadata": {},
   "source": [
    "Now, let's use the AWS Python SDK `boto3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab536f45-a505-4341-83d4-a2cf64039b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a `bedrock` client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc42da1-a040-4de2-bf1e-ed08ef3ad5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "#Create the connection to Bedrock\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name='us-west-2', \n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac6718-0a38-40c1-a31d-0bc6d8301e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With `Anthropic (Claude v3 (Sonnet))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d357de4b-8c0d-4317-b14e-b099adbe722c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"What is L in LLM means\"\"\"\n",
    "\n",
    "body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": [\n",
    "                 {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_data\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "body = json.dumps(body) # Encode body as JSON string\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8cb2f-0478-4697-86d0-590fbf8be22d",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c204dee-e262-4c40-becf-8af9255f6145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de6d86-bff5-4a73-a2ff-c7ec38c49d81",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe2e98a-515f-4896-89fe-d96f1e4b00c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of AI and natural language processing, LLM stands for \"Large Language Model.\"\n",
      "\n",
      "The key points about LLMs are:\n",
      "\n",
      "L - Large: These models have a massive number of parameters, often in the billions, which allows them to capture and model incredibly complex linguistic patterns and knowledge.\n",
      "\n",
      "L - Language: They are trained on vast amounts of text data from the internet and books to understand and generate human-like language.\n",
      "\n",
      "M - Model: They utilize advanced neural network architectures like transformers to function as general language models capable of understanding and generating text.\n",
      "\n",
      "Some well-known examples of LLMs are:\n",
      "\n",
      "- GPT-3 by OpenAI\n",
      "- LaMDA by Google\n",
      "- PaLM by Google\n",
      "- BLOOM by Hugging Face\n",
      "- Me (Claude) - an LLM created by Anthropic\n",
      "\n",
      "LLMs can be fine-tuned on specific tasks, but their key capability is general language understanding and generation across many domains. Their scale allows them to perform well on many natural language tasks like question-answering, text summarization, translation, and even creative writing.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get(\"body\").read())\n",
    "\n",
    "for output in response_body.get(\"content\", []):\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656ce38-e3dd-492f-b035-8a708cbe34b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Syntax Multi-Modal models from `Anthropic Claude v3 Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79dcda90-954d-4c0c-92a2-cb2479f0adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"images/cat.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": base64_string\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Write me a detailed description of this photo.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the payload to bytes\n",
    "body_bytes = json.dumps(payload['body']).encode('utf-8')\n",
    "\n",
    "# Invoke the model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body_bytes,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3482f6-bfa5-4006-867e-e5a35a089e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image depicts a cute and expressive cartoon cat. The cat has large, round eyes with brown irises that give it an endearing and friendly expression. Its mouth is open in a smile, revealing some teeth.\n",
      "\n",
      "The cat's fur is striped in shades of orange and white, reminiscent of a tabby cat pattern. Its face has white fur around the mouth area, and its ears are pointed with pink insides.\n",
      "\n",
      "The cat's body is shown sitting upright, with its front paws on the ground and its tail curled around behind it. The paws have distinct white toes or pads.\n",
      "\n",
      "The illustration has a simple gray background, allowing the vibrant and cheerful colors of the cat to stand out prominently. Overall, the image conveys a playful and adorable portrayal of a animated feline character through its exaggerated features and bright colors.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('content')[0].get('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f57584-eca6-4602-a6a6-ab39528d13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b918e6-78a1-4426-813a-0608892089bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List of all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d421313-4275-4ab2-824c-ebd543345574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon.titan-tg1-large',\n",
       " 'amazon.titan-embed-g1-text-02',\n",
       " 'amazon.titan-text-lite-v1:0:4k',\n",
       " 'amazon.titan-text-lite-v1',\n",
       " 'amazon.titan-text-express-v1:0:8k',\n",
       " 'amazon.titan-text-express-v1',\n",
       " 'amazon.titan-embed-text-v1:2:8k',\n",
       " 'amazon.titan-embed-text-v1',\n",
       " 'amazon.titan-embed-image-v1:0',\n",
       " 'amazon.titan-embed-image-v1',\n",
       " 'amazon.titan-image-generator-v1:0',\n",
       " 'amazon.titan-image-generator-v1',\n",
       " 'stability.stable-diffusion-xl',\n",
       " 'stability.stable-diffusion-xl-v0',\n",
       " 'stability.stable-diffusion-xl-v1:0',\n",
       " 'stability.stable-diffusion-xl-v1',\n",
       " 'ai21.j2-grande-instruct',\n",
       " 'ai21.j2-jumbo-instruct',\n",
       " 'ai21.j2-mid',\n",
       " 'ai21.j2-mid-v1',\n",
       " 'ai21.j2-ultra',\n",
       " 'ai21.j2-ultra-v1',\n",
       " 'anthropic.claude-instant-v1:2:100k',\n",
       " 'anthropic.claude-instant-v1',\n",
       " 'anthropic.claude-v2:0:18k',\n",
       " 'anthropic.claude-v2:0:100k',\n",
       " 'anthropic.claude-v2:1:18k',\n",
       " 'anthropic.claude-v2:1:200k',\n",
       " 'anthropic.claude-v2:1',\n",
       " 'anthropic.claude-v2',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
       " 'cohere.command-text-v14:7:4k',\n",
       " 'cohere.command-text-v14',\n",
       " 'cohere.command-light-text-v14:7:4k',\n",
       " 'cohere.command-light-text-v14',\n",
       " 'cohere.embed-english-v3',\n",
       " 'cohere.embed-multilingual-v3',\n",
       " 'meta.llama2-13b-chat-v1:0:4k',\n",
       " 'meta.llama2-13b-chat-v1',\n",
       " 'meta.llama2-70b-chat-v1:0:4k',\n",
       " 'meta.llama2-70b-chat-v1',\n",
       " 'meta.llama2-13b-v1:0:4k',\n",
       " 'meta.llama2-13b-v1',\n",
       " 'meta.llama2-70b-v1:0:4k',\n",
       " 'meta.llama2-70b-v1',\n",
       " 'mistral.mistral-7b-instruct-v0:2',\n",
       " 'mistral.mixtral-8x7b-instruct-v0:1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all foundation models\n",
    "all_llms = [ model['modelId'] for model in bedrock.list_foundation_models()['modelSummaries']]\n",
    "all_llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f983c62-5db4-4939-99cd-01ed5cf50ece",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Mistral (mixtral-8x7b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9fd10c-b83f-45c4-9e1a-9b55e1736354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"<s>[INST]Craft a Python function to convert Celsius to Fahrenheit. If water boils at 100Â°C, what's that in Fahrenheit?[/INST]\"\"\"\n",
    "\n",
    "body = json.dumps({ \n",
    "    'prompt': prompt_data,\n",
    "    'max_tokens': 200,\n",
    "    'top_p': 0.9,\n",
    "    'temperature': 0.2,\n",
    "})\n",
    "\n",
    "\n",
    "modelId = 'mistral.mixtral-8x7b-instruct-v0:1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e979-9d72-4ab7-9acb-3afc89687213",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a285cc8b-b9df-4339-8b69-8e9594a8e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                        modelId=modelId, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15918b5d-1068-4d93-9309-c1d3f2e903b6",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e49eef-0d1b-43c2-a6a6-5a8aca398db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a simple Python function to convert Celsius to Fahrenheit:\n",
      "\n",
      "```python\n",
      "def celsius_to_fahrenheit(celsius):\n",
      "    return (celsius * 9/5) + 32\n",
      "```\n",
      "\n",
      "Now, let's use this function to convert 100 degrees Celsius to Fahrenheit:\n",
      "\n",
      "```python\n",
      "print(celsius_to_fahrenheit(100))\n",
      "```\n",
      "\n",
      "When you run this code, it will output `212.0`, which is the boiling point of water in Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('outputs')[0].get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424ed56-7725-4b51-b027-ee53b2de1b48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With `Amazon Titan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a9ba82-62d6-49bd-ac1e-967d5bc59d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"Write me a poem about apples\"\"\"\n",
    "\n",
    "text_gen_config = {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"stopSequences\": [], \n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "\n",
    "body = json.dumps({\n",
    "                        \"inputText\": prompt_data,\n",
    "                        \"textGenerationConfig\": text_gen_config  \n",
    "                    })\n",
    "\n",
    "model_id = 'amazon.titan-tg1-large'\n",
    "accept = 'application/json' \n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc650c9-a75c-4ed4-ae0a-e3e0a5e38914",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3702c51b-a622-4635-aeb7-e3309013ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "                                            body=body, \n",
    "                                            modelId=model_id, \n",
    "                                            accept=accept, \n",
    "                                            contentType=content_type\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e7285-e061-4886-934f-904da5d43fa7",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06be453a-62d5-400e-aca1-f3b1beb0dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is a poem about apples:\n",
      "\n",
      "Apples are so round and bright,\n",
      "They make my mouth water with delight.\n",
      "Their skin is so smooth and crisp,\n",
      "I can't help but eat them every day.\n",
      "\n",
      "They come in red, yellow, and green,\n",
      "But my favorite is the pink and serene.\n",
      "I eat them with peanut butter,\n",
      "They're the perfect snack for any time.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df4096-baca-49b0-a712-c23ef975b70f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2 style=\"color: #D35400;\">Deploy your own <code style=\"background-color: #f5f5f5; color: #EB5444;\">chatbot</code>  using Amazon Bedrock deployed on AWS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad8af4-fca7-4d83-a890-d1f8215519e9",
   "metadata": {},
   "source": [
    "### Demo\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"images/chatbodbedrock.gif\" alt=\"Claude 3 Benchmark\" style=\"width: 100%;\"/>\n",
    "</div>\n",
    "\n",
    "### Architecture\n",
    "\n",
    "It's an architecture built on AWS managed services, eliminating the need for infrastructure management. Utilizing Amazon Bedrock, there's no need to communicate with APIs outside of AWS. This enables deploying scalable, reliable, and secure applications.\n",
    "\n",
    "- [Amazon DynamoDB](https://aws.amazon.com/dynamodb/): NoSQL database for conversation history storage\n",
    "- [Amazon API Gateway](https://aws.amazon.com/api-gateway/) + [AWS Lambda](https://aws.amazon.com/lambda/): Backend API endpoint ([AWS Lambda Web Adapter](https://github.com/awslabs/aws-lambda-web-adapter), [FastAPI](https://fastapi.tiangolo.com/))\n",
    "- [Amazon CloudFront](https://aws.amazon.com/cloudfront/) + [S3](https://aws.amazon.com/s3/): Frontend application delivery ([React](https://react.dev/), [Tailwind CSS](https://tailwindcss.com/))\n",
    "- [AWS WAF](https://aws.amazon.com/waf/): IP address restriction\n",
    "- [Amazon Cognito](https://aws.amazon.com/cognito/): User authentication\n",
    "- [Amazon Bedrock](https://aws.amazon.com/bedrock/): Managed service to utilize foundational models via APIs. Claude is used for chat response and Cohere for vector embedding\n",
    "- [Amazon EventBridge Pipes](https://aws.amazon.com/eventbridge/pipes/): Receiving event from DynamoDB stream and launching ECS task to embed external knowledge\n",
    "- [Amazon Elastic Container Service](https://aws.amazon.com/ecs/): Run crawling, parsing and embedding tasks. [Cohere Multilingual](https://txt.cohere.com/multilingual/) is the model used for embedding.\n",
    "- [Amazon Aurora PostgreSQL](https://aws.amazon.com/rds/aurora/): Scalable vector store with [pgvector](https://github.com/pgvector/pgvector) plugin\n",
    "\n",
    "![](images/arch.png)\n",
    "\n",
    "### Code \n",
    "\n",
    "[Deployment Code](01.Bedrock_Claude_Chat/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595c4ac-1bf2-4161-a9b5-35dd777d0aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
